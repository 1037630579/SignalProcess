# Author: Kaituo Xu, Fan Yu
import  numpy as np
def forward_algorithm(O, HMM_model):
    """HMM Forward Algorithm.
    Args:
        O: (o1, o2, ..., oT), observations
        HMM_model: (pi, A, B), (init state prob, transition prob, emitting prob)
    Return:
        prob: the probability of HMM_model generating O.
    """
    pi, A, B = HMM_model
    T = len(O)
    N = len(pi)
    prob = 0.0
    # Begin Assignment
    # Put Your Code Here
    #初始前验概率
    pre_prob = np.zeros((T,N))
    #初始值
    for i in range(N):
        pre_prob[0][i] = pi[i]*B[i][O[0]]
    #递推
    for t in range(1,T):
        for i in range(N):
            tmp = 0
            for j in range(N):
                tmp +=pre_prob[t-1][j]*A[j][i]
            pre_prob[t][i] = tmp*B[i][O[t]]
    #终止
    prob = np.sum(pre_prob[T-1][:])
    # End Assignment
    return prob


def backward_algorithm(O, HMM_model):
    """HMM Backward Algorithm.
    Args:
        O: (o1, o2, ..., oT), observations
        HMM_model: (pi, A, B), (init state prob, transition prob, emitting prob)
    Return:
        prob: the probability of HMM_model generating O.
    """
    pi, A, B = HMM_model
    T = len(O)
    N = len(pi)
    prob = 0.0
    # Begin Assignment

    # Put Your Code Here

    #T-1时刻后验概率
    post_prob = np.ones((T,N))
    for t in range(T-1,0,-1):
        for i in range(N):
            tmp = 0
            for j in range(N):
                tmp += A[i][j]*B[j][O[t]]*post_prob[t][j]
            post_prob[t-1][i] = tmp
    prob = np.sum([pi[i]*B[i][O[0]]*post_prob[0][i] for i in range(N)])
    # End Assignment
    return prob
 

def Viterbi_algorithm(O, HMM_model):
    """Viterbi decoding.
    Args:
        O: (o1, o2, ..., oT), observations
        HMM_model: (pi, A, B), (init state prob, transition prob, emitting prob)
    Returns:
        best_prob: the probability of the best state sequence
        best_path: the best state sequence
    """
    pi, A, B = HMM_model
    T = len(O)
    N = len(pi)
    best_prob, best_path = 0.0, []
    # Begin Assignment

    # Put Your Code Here
    one_drt = np.zeros((T, N))
    max_point = np.zeros((T, N))
    #初始化
    for i in range(N):
        one_drt[0][i] = pi[i]*B[i][0]
        max_point[0][i] = 0
    #递推
    for t in range(1, T):
        for i in range(N):
            for j in range(N):
                one_drt[t][i] = max(one_drt[t][i],one_drt[t-1][j]*A[j][i]*B[i][O[t]])
            for j in range(N):
                max_point[t][i] = np.where(one_drt[t-1][j]*A[j][i]>max_point[t][i], j, max_point[t][i])
    #递归
    for t in range(T-1,-1,-1):
        best_prob = max(one_drt[t][:])
        for i in range(N):
            if best_prob == one_drt[t][i]:
                best_path.insert(0,max_point[t][i])
    # End Assignment
    return best_prob, best_path


if __name__ == "__main__":
    color2id = { "RED": 0, "WHITE": 1 }
    # model parameters
    #初始化隐藏状态分布
    pi = [0.2, 0.4, 0.4]
    #状态转移
    A = [[0.5, 0.2, 0.3],
         [0.3, 0.5, 0.2],
         [0.2, 0.3, 0.5]]
    #观测概率
    B = [[0.5, 0.5],
         [0.4, 0.6],
         [0.7, 0.3]]
    # input
    #观测序列
    observations = (0, 1, 0)
    #初始化HMM模型
    HMM_model = (pi, A, B)
    # process
    observ_prob_forward = forward_algorithm(observations, HMM_model)
    print(observ_prob_forward)

    observ_prob_backward = backward_algorithm(observations, HMM_model)
    print(observ_prob_backward)

    best_prob, best_path = Viterbi_algorithm(observations, HMM_model) 
    print(best_prob, best_path)
